The Lancet Commission on malaria eradication received widespread attention this week with its claim that the disease could be eradicated by 2050. This would be a very welcome achievement, as malaria currently kills about 435,000 people – predominantly children – each year. The report argues that the key to eradicating malaria is the application of existing and new technology, coupled with £1.6bn extra annual funding. Unfortunately, this solution is unlikely to be successful because it fails to address the underlying causes of malaria: grinding poverty and state incapacity. Malaria is often referred to as a “tropical disease”. On the face of it, this seems reasonable, as the majority of cases and deaths do occur in tropical regions, predominantly in sub-Saharan Africa. Until relatively recently, however, malaria was endemic in many temperate regions, including much of Europe. In England, malaria was referred to as “marsh fever” or “the ague”. It was mentioned in eight of Shakespeare’s plays, serving as a metaphor for all things evil. Malaria was particularly common in what Caliban referred to in The Tempest as the “unwholesome fen” – seen by some as the southern and eastern coastal marshlands, where brackish water provided a fertile breeding ground for the Anopheles atroparvus mosquito. Historian Mary Dobson notes that in the 17th and 18th centuries crude death rates were two or three times higher in the wetlands than in neighbouring areas. It was common for marshland vicars to refuse to live in their parishes and for wealthy landowners to reside away from their farms to avoid the bad air or miasma – the sulphurous smell caused by anaerobic bacteria in the mud – that they believed to be the cause of malaria. Daniel Defoe wrote how farmers in the Essex marshes “had from five to six, to fourteen or fifteen wives”, because the men, having grown up in the area, were to some extent immune to the ague, while their partners quickly succumbed to the disease. When a wife died, “the men would go to the uplands again and fetch another”. In England, malaria declined markedly in the 18th and 19th centuries due to a variety of factors. Increased land reclamation and improved drainage diminished the mosquitoes’ habitat; advancements in agricultural technology reduced the number of people working on the land; the rural population fell as a result of the industrial revolution and urbanisation; and improved supplies of quinine reduced the presence of the malaria parasite in its human host. Malaria was much more common and deadly in southern Europe, especially Italy. The word malaria is a contracted form of the Italian for bad air (mala aria). Malaria was endemic in the Italian peninsular since at least antiquity. A particularly bad epidemic appears to have occurred in central Italy in the fifth century. Over the past few years archeologists have uncovered the bodies of more than 50 infant victims of malaria in La necropoli dei bambini in Lugnano, Umbria. Items associated with witchcraft, including raven talons, toad bones and body parts of puppies, were buried alongside the children. The hands and feet of a three-year-old girl were weighed down with stones, a practice that was thought to keep the dead in their graves, and an older child was buried with a rock in his mouth. This points to the fear that this malaria epidemic must have been created in the community. It has even been argued that the malaria epidemic in fifth century Italy weakened the local population to such an extent that it contributed to the fall of the Roman empire, with the Visigoths sacking Rome in 410 and Odoacer overthrowing the last western emperor in 476. At the end of the 19th century in Italy, there were 2m malaria cases each year in a population of 30 million, and the disease killed between 15,000 and 20,000 annually. Malaria mortality and morbidity declined sharply in the early 20th century as a result of state intervention, which included free quinine, as well as measures to reduce places where mosquitoes could breed, including draining wetlands and spraying standing water with chemicals. Europe became malaria-free in 1975. In England and the rest of north-west Europe this occurred primarily as result of broad-based economic development, whereas state intervention played more of a role in Italy and southern Europe. Either way, malaria eradication was just one aspect of the more wide-reaching march out of poverty and disease that occurred in Europe in the 19th and 20th centuries. The slave trade, colonialism, unfair trade relations, and structural adjustment have so damaged politics and society in sub-Saharan Africa that this route is not open to its hundreds of millionsof inhabitants. Better technology and more money for malaria eradication do not address these underlying causes of poverty and disease. It is not a coincidence that Nigeria has the highest number of malaria cases in the world (53.7m cases or 25% of the global total) and the highest number of people living in extreme poverty (94.3 million). The Democratic Republic of the Congo (DRC) comes second for both malaria burden (25m cases, 11% of the global total) and extreme poverty (60.1 million people). The focus on technology and money is ahistorical, as it overlooks the way in which malaria was eliminated in Europe. It is depoliticising because it ignores the fact that grinding poverty and state incapacity are the underlying reasons why malaria is endemic in sub-Saharan Africa and that these conditions are, to a large extent, a consequence of interference by high-income countries. Even if advancements like gene-drive technologies are successful at eradicating malaria, without profound economic and political reforms to address extreme poverty and improve primary healthcare, sub-Saharan Africa will remain vulnerable to the emergence of new infectious diseases – as demonstrated by the Ebola outbreak in west Africa a few years ago and the current Ebola outbreak in DRC. • Jonathan Kennedy is a lecturer in global health at Queen Mary University of London