The Guardian is right to express legitimate concerns about the opacity of machine learning systems and attempts to replicate what humans do best (Editorial, 23 September), and we welcome this. However, as founders of the Institute for Ethical AI in Education (IEAIED) we believe these problems must be overcome in order to ensure people are able to benefit from artificial intelligence, not just fear it. There are highly beneficial applications of machine learning. In education, for example, this innovation will enable personalised learning for all and is already enabling individualised learning support for increasing numbers of students. Well-designed AI can be used to identify learners’ particular needs so that everyone – especially the most vulnerable – can receive targeted support. Given the magnitude of what people have to gain from machine learning tools, we feel an obligation to mitigate and counteract the inherent risks so that the best possible outcomes can be realised. First, we must not accept that machine learning systems have to be block-boxes whose decisions and behaviours are beyond the reach of human understanding. Explainable AI (XAI) is a rapidly developing field, and we encourage education stakeholders to demand and expect high levels of transparency. There are also further means by which we can ethically derive benefits from machine learning systems, while retaining human responsibility. Another approach to benefiting from AI without being undermined by a lack of human oversight is to consider that AI is not bringing about these benefits single-handedly. Genuine advancement arises when AI augments and assists human-driven processes and skills. Machine learning is a powerful tool for informing strategy and decision-making, but people remain responsible for how that information is harnessed. Incorporating ethics into the design and development of AI-driven technology is vital, and we currently rely on programmes such as UCL Educate, an accelerator for education SMEs and startups, to instil that ethos in innovation from the concept stage. Crucially, though, we must inform the public at large about AI – what it is and what benefits can be derived from its use – or we risk alienating people from the technology that already forms part of their everyday lives. Worse still, we risk causing alarm and making them fearful.Prof Rose Luckin Professor of learner centred design at UCL Institute of Education and director of UCL Educate Sir Anthony Seldon Vice-chancellor, University of Buckingham Priya Lakhani Founder CEO, Century Tech • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition