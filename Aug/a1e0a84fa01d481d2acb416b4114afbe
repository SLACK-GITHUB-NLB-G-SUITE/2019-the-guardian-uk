Who even knows what’s real any more? We’ve never before had access to so much information – search online for pretty much anybody and you’ll turn up personal details that a 90s private detective might have deemed excessive – but we are also bombarded with disinformation. Fake news has taken over much of the internet (and the lexicon: it was Collins Dictionary’s word of the year in 2017) but it isn’t just headlines that are being skewed by the anonymity of online spaces, in particular social media. Facebook has this week been criticised for failing to take proper action against a phenomenon that has thrived on its platform: fake reviews. After a six-month investigation, the Competition and Markets Authority wrote to both Facebook and eBay in June about adverts on their platforms seeking fake reviewers, but the consumer group Which? has found that many of the groups that were advertising remain active. Outfits known as “review farms” incentivise individuals to post positive reviews of products in exchange for money, freebies or other perks. Sometimes the individual leaving the review or rating has never come into contact with the product in question, while in other instances they are paid to order it and say nice things even if, say, a torch is less than illuminating. Uber drivers' ratings tend to be artificially high, while Deliveroo riders get bad reviews for mistakes they didn't make Fake reviewing is big business. Three-quarters of us are thought to consult online reviews before deciding on a purchase, meaning the verdicts of strangers are influencing billions of pounds-worth of expenditure (the CMA has estimated that as much as £23bn of UK consumer spending might be affected by fake reviews). And it isn’t just product reviews being manipulated. Service industries rely hugely on ratings and rankings. The Vice journalist Oobah Butler demonstrated just how easy it is to game “popularity” algorithms by managing to, over a period of six months, get his restaurant to the number one spot for London eateries on TripAdvisor. It didn’t even exist. It’s the type of human reviews that Butler solicited from family and friends that are the cornerstone of the fight against fake reviewing. As internet literacy expands, and consumers become more adept at spotting bot (automated) reviews, the demand for human reviewers has surged. (Butler used to do this for work, being paid £10 a pop to write appreciative things about restaurants he’d never set foot in – and he’s a great writer, I can imagine him persuading many readers to visit.) In response, platforms are being urged to hire humans to weed out fake reviews rather than rely on algorithms, just as it’s no longer considered enough for social media companies to rely on algorithms to root out abusive content, sham news pages and fake comments. There has always been an element of self-selection bias when it comes to reading reviews. (Who has the time to write them? And will my opinion really align with the type of person whose first priority on coming back from holiday is to moan about the breakfast buffet?) But now, in a gig economy and one-click culture, reviews have taken on new dimensions. Feedback doesn’t even need to be false to be rendered pointless or harmful. From my time doing tech reporting, I know the huge pressure Uber drivers are under to maintain a high rating (they are at risk of deactivation if it falls beneath 4.6) . This means that I always give a driver a five-star rating, even if the route they took was awful or the car stank of fags. I am not the only one: a New York University study, titled Reputation Inflation, found the phenomenon to be widespread, leaving drivers’ average ratings artificially high. On the flip side are the Deliveroo riders who have have been given bad reviews for mistakes that were the responsibility of the restaurant. Busy people don’t care about this distinction. Neither of these types of review are fake, as such, but both demonstrate problems inherent with today’s ratings culture. Nefarious operators are incentivising: hacking into accounts or scraping user data to send out unsolicited products, in a practice known as brushing. Online reviews have now even been weaponised as a tool for abuse. Witness the misogynist campaign to engineer a low score for Captain Marvel – Marvel’s first female-led superhero film – on the review aggregator Rotten Tomatoes. I will always read reviews before buying a product or visiting a place, but I know of the problems with online reviews. There is one type of fake review, though, that I can appreciate: the ones done for laughs. Who can forget the time in 2012 that Amazon was bombarded with feedback for the patently ridiculous and sexist biros marketed at women? “It’s good,” one reviewer noted, “that BIC are finally doing something to aid the plight of women.” • Hannah Jane Parkinson is a Guardian columnist