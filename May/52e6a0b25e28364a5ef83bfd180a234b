Tenants in a New York City apartment complex are fighting their landlord’s effort to install a facial recognition system to access parts of the buildings, calling it an affront to their privacy rights. The row, which the tenants believe could become an important test case, comes as concern about the spread of facial recognition systems has grown across the US and globally, with law enforcement agencies increasingly relying on the tool. San Francisco this month became the first US city to ban city police and government agencies from using it. Private firms are also increasingly keen on the technology. At Atlantic Plaza Towers in the Brownsville neighborhood of Brooklyn, the landlord, Nelson Management Group, is moving to install a new system to control entry into the buildings. It would use facial recognition to open the front door for recognized tenants rather than traditional keys or electronic key fobs. We do not want to be tagged like animals More than 130 tenants have, however, filed a formal complaint with the state seeking to block the application. “We do not want to be tagged like animals,” said Icemae Downes, who has lived at Atlantic Plaza Towers since it opened 51 years ago. “We are not animals. We should be able to freely come in and out of our development without you tracking every movement.” Some residents also fear the move reflects the spreading pressures of gentrification further into the east of Brooklyn, and a desire to attract white, higher-income residents in the buildings, whose tenants are mostly black. They say there is already a culture of surveillance and that if they are suspected of breaking one of the building’s rules, they might find an image of themselves pushed under their doors. The management firm insists the sole purpose of the changes would be to use the latest technology to make the buildings safer, and it described claims that it is trying to change the tenant makeup as baseless. While government agencies’ use of facial recognition has been under the spotlight, much less is known about the extent of its use in the private sector, experts say, because freedom of information laws do not apply. “The vast majority of commercial deployments are secret,” said Alvaro Bedoya, the founding director of the Center on Privacy & Technology at Georgetown Law. “This turns people’s expectations upside down about their privacy. In 2019, most people expect that when they log online, they’re going to be tracked in some way,” he said. “In public, in real life, most people still think they can be a face in the crowd. And up until the deployment of facial recognition technology, they were right … This lets people be tracked in the real world like they are online, and I think that is a pretty basic invasion into our lives.” The Brooklyn tenants believe their challenge could have a wider impact as more landlords begin to experiment with facial recognition at residential buildings. “We’re not going to stand for it, and we’re asking other renters in the state, not just in the city, to join us – because it’s coming to your house next,” Downes said. The two brick high-rises in Brownsville already have security cameras watching the grounds, doorways, elevators and halls. They are also staffed by security guards, and residents must use key fobs to get inside – so tenants are dubious of the landlord’s explanation that facial recognition is necessary to improve security. “There’s cameras at every inch of this place,” said Tranae Moran, 27. “It’s endless. They have every piece of data we own. With that equipment, they will have every piece of information that is associated with us, and that’s not necessary.” She is afraid that the biometric information collected for the new system would be abused. “I’m afraid of it being shared with third-party agencies. I’m afraid of it being shared with the police. I’m afraid of it being shared with anyone – advertising companies, just everyone. It’s just very sensitive information that I feel our landlord should not have,” she said. Already, tenants say that security camera footage is carefully monitored. Residents who walk their dogs in the wrong place or enter the building with a box that looks like it contains a forbidden appliance say they might get an image of the alleged transgression slid under their doors, with a warning notice or a fine. So the residents fighting the application suspect the proposal has less to do with improving their own security, and more with attracting new tenants to the buildings in an area of Brooklyn primed for gentrification. “He doesn’t want Spanish. He doesn’t want black. He wants white people to come into the neighborhood,” Moran said. The tenants’ complaint, in addition to privacy concerns, cites research that has found that facial recognition algorithms are less accurate when used on black people and women, as compared with white people and men. The Nelson Management Group spokesman Chris Santarelli said claims the group wanted to change the demographics in the towers are “baseless and don’t correspond with facts”, adding that tenant turnover has fallen since the group bought the towers. Santarelli said the company was pursuing “cutting-edge technology at all our properties to create a safer environment for tenants and provide the highest-quality housing in the rent-stabilized market. “The sole goal of implementing this technology is to advance that priority and support the safety and security of residents,” he said. “We have yet to install anything having to do with a facial recognition system. We have engaged a leading provider of security technology for proposed upgrades, which has assured ownership that data collected is never exposed to third parties and is fully encrypted.” Santarelli said the complex already has extensive security and the “proposed new technology would compliment those safety amenities.” The buildings are governed by New York’s rent stabilization laws, so a change like the one Nelson Management Group is proposing must be approved by the state department of homes and community renewal (HCR). It is the first application for a facial recognition system the agency has received and it is currently“under review”, said the HCR spokeswoman Charni Sochet. In New York, buildings including Knickerbocker Village in Manhattan and the Morris Avenue Apartments in the Bronx have implemented facial recognition systems. But their installation has not yet been put to the legal or regulatory test. “The field is so unregulated,” said Mona Patel, an attorney at Brooklyn Legal Services, which is representing the tenants. “There aren’t any rules that would govern it, because there aren’t any laws on facial recognition entry systems.” The group argues that rent stabilization law requires a landlord to give a tenant a new lease on the same terms as their old lease – and that requiring tenants to turn over their biometric information is a violation of those terms. The residents have only the landlord’s “pinky promise” that he will not share the data with police, immigration authorities, or advertisers, the legal papers say. “A state agency should not require state residents to surrender their confidential information to their landlord, who can use it however he wishes,” Patel said. Residents are right to be concerned, said Bedoya. Tracking when a resident enters and leaves their building can reveal all kinds of information, he said, from the job they work to what religious services they attend to whether they’re cheating on their spouse. “Your work life, your love life, your family life, your religious life – all of that is opened up for display to people using facial recognition to track your comings and goings from the building,” he said. Follow Guardian Cities on Twitter, Facebook and Instagram to join the discussion, catch up on our best stories or sign up for our weekly newsletter