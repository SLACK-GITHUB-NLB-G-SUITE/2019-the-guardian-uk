Sometimes, it is the very ordinariness of a scene that makes it terrifying. So it was with a clip from last week’s BBC documentary on facial recognition technology. It shows the Metropolitan police trialling a facial recognition system on an east London street. A man tries to avoid the cameras, covering his face by pulling up his fleece. He is stopped by the police and forced to have his photo taken. He is then fined £90 for “disorderly behaviour”. If you want to protect your privacy, you must have something to hide “What’s your suspicion?” someone asks the police. “The fact that he’s walked past clearly masking his face from recognition,” replies one of the plainclothes police operating the system. If you want to protect your privacy, you must have something to hide. And if you actually do something to protect your privacy, well, that’s “disorderly behaviour”. There is considerable panic in the west about the Chinese tech firm Huawei acting as a Trojan horse for Beijing. But perhaps we should worry less about the tech company than about the social use of technology. Much has been written about Beijing’s development of a dystopian surveillance state. It’s not just in China, though, that what one observer has called “algorithmic governance” is beginning to take hold. As the tech entrepreneur Maciej Ceglowski pointed out in testimony to a US Senate committee hearing this month: “Until recently, even people living in a police state could count on the fact that the authorities didn’t have enough equipment or manpower to observe everyone, everywhere, and so enjoyed more freedom from monitoring than we do living in a free society today.” Britain has long been one of the most closely monitored societies in the world. There are at least 4.9 million CCTV cameras in Britain – one for every 14 people. Some estimates suggest that 20% of all CCTV cameras are in the UK. Now Britain is at the forefront of the rollout of facial recognition technology. Police forces are using it to monitor shopping centres, music festivals, sports events and political demonstrations. The technology is currently beset with myriad problems. It is inaccurate – according to the campaign group Big Brother Watch, in police trials“a staggering 95% of ‘matches’ wrongly identified innocent people” – and there is a major issue of racial bias in the algorithms. The real problem, however, the technology writer Jamie Bartlett suggests, is not that it doesn’t work, but, rather, that it may work very well. “Despite the problems,” he argues, “I expect it will be very effective at tackling crime and keeping us safe. At what cost?” In other words, how much do we treasure privacy? Are we all willing to be treated like that man on an east London street? Almost without realising, we have created an entire infrastructure of surveillance Nor is it just facial recognition technology that’s the issue here. Almost without realising, we have created an entire infrastructure of surveillance. If you’re reading this online, you’re being tracked. If you bought a print version of the newspaper at a supermarket, your purchase was probably recorded. Every time you go shopping, use public transport, make a phone call, engage with social media, you’re likely to have been tracked. Surveillance is at the heart, too, of “smart cities”. From Amsterdam to Singapore, from Dubai to Toronto, cities across the globe are embracing technology to collect data on citizens, ostensibly to improve public services and make urban spaces function better. What smart cities also enable is a new form of policing. As the mayor of Rio de Janeiro said of the “integrated urban command centre” built in preparation for the 2016 Olympics and the World Cup, the system “allows us to have people looking into every corner of the city, 24 hours a day, seven days a week”. Buses that run on time and rubbish that is efficiently cleared are good things (though in most smart cities, and in Rio especially, neither actually happens). There is, however, more to the good life than an ordered city. Human flourishing, as Ceglowski pointed out to the US Senate, requires the existence of a sphere of life outside public scrutiny; not only within the intimacy of the home but also in semi-private spaces such as the workplace or the church or the pub. It’s that kind of space shielded from scrutiny that increasingly is vanishing. In a number of US cities, such as San Francisco and Oakland, there have been pushbacks against mass surveillance. Yet, as Ceglowski observed, one of the features of the “new world of ambient surveillance” is that “we cannot opt out of it, any more than we might opt out of automobile culture by refusing to drive”. That is possibly the most disturbing thought of all. • Kenan Malik is an Observer columnist