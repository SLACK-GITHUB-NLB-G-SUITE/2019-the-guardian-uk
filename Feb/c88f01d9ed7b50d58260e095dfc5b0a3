The UK government is to ask Tinder and Grindr what measures they are taking to ensure child safety, after claims of exploitation on dating apps. It was reported on Sunday that police have investigated more than 30 cases of child rape since 2015 where victims evaded age checks on dating apps. Jeremy Wright, the secretary of state for digital, culture, media and sport, said: “I will be writing to these companies asking what measures they have in place to keep children safe from harm, including verifying their age. If I’m not satisfied with their response, I reserve the right to take further action.” Other data released to the Sunday Times under freedom of information laws revealed there have been a further 60 further cases of child sexual offences via online dating services, including grooming, kidnapping and violent sexual assault. The youngest victim was said to be eight years old. Last week a man who spent a night with a 12-year-old girl he thought was 19 and whom he had met on a popular adult dating app was jailed for two and a half years. Carl Hodgson, 28, who pleaded guilty to a number of charges, invited the child to his flat in Manchester city centre a few days after they first made contact via an app. The victim used a different name on her dating app profile and falsely stated she was 19, Manchester crown court was told. Social media companies are facing renewed demands from the government to protect children from harmful online content, amid growing concerns over suicide and self-harm among teenagers. Last month Matt Hancock, the health secretary, warned companies including Facebook, Google and Twitter that he would use the law to force them to act should they fail to remove inappropriate content. Grindr told the Sunday Times: “Any account of sexual abuse or other illegal behaviour is troubling to us as well as a clear violation of our terms of service. Our team is constantly working to improve our digital and human screening tools to prevent and remove improper underage use of our app.” Tinder said it used both automated and manual tools to moderate users, including scanning profiles for “red flag” images, and said it also depended on users to report profiles that may belong to a minor. A spokeswoman said: “We utilise a network of industry-leading automated and manual moderation and review tools, systems and processes – and spend millions of dollars annually – to prevent, monitor and remove minors and other inappropriate behaviour from our app. We don’t want minors on Tinder.”