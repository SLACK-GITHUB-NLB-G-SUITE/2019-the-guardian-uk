When new technology destroyed their livelihood in the early 19th century, a group of workers in northern England took matters into their own hands. They were alpha males, the fittest of the farm workers with the best gig of their time: whacking and cutting sheets of woven wool into shape and then “cropping” the rough surface to make it smooth enough to become stockings for the aristocracy. It was high-yield, value-added work, earning them three times the average wage for half the time on the job. But when mechanical stocking frames were developed that could do the job six times faster, they found themselves surplus to requirements. What work remained was paid less, the hours were longer, and production had moved indoors, leaving workers “stunted, enfeebled and depraved”. The first attack came in a village called Bulwell. A group of croppers broke into a house and smashed up the offending stocking frames. They called themselves “Luddites”, a whimsical reference to a folktale about a young cropper who, when beaten by his master, retaliated by destroying his frame. The whole thing went viral. Attacks spread from town to town under cover of darkness, the croppers destroying the technology that was robbing them of their livelihood. Contrary to legend, the Luddites were not opposed to the new technology. What they wanted was a fairer distribution of the profits from the industrialists and a more gradual take-up of the machinery to give them time to learn new trades. It was the breach of the social contract rather than the introduction of the new machines that fuelled the resistance. All the Luddites wanted was a planned and fair transition rather than transformative change with no regard for the consequences. The Luddites were ultimately crushed, but their resistance sparked a fire that ignited in newly formed guilds and trade unions demanding workers’ rights. They would also inspire the Chartist movement that demanded universal suffrage and in turn compelled John Edward Taylor to establish the Guardian. These waves of activism would secure the Factory Acts that were passed between 1833 and 1853 regulating child labour, mandating regular safety inspections and establishing a 10-hour working day. These laws took the crueller edges off the disruption of the first industrial revolution and created a social safety net for the fairer distribution of wealth through higher wages and better conditions – benefits that would flow to workers for the next two centuries. From our vantage point, this arc from the stocking frames of the Luddites to the Factory Acts makes total sense: a transformative technological change, its adaptation unfettered by regulation, and then the demand for a collective response as the implications of those changes become clearer. The evolution of the web is following a similar arc. Where we are now asking ourselves how we can assert some sort of control to both maximise the benefits and mitigate the damage that is becoming increasingly apparent. Across the globe, the mood for some sort of intervention is palpable. After nearly two decades of believing that the role of government was to facilitate the web and then get out of the way, people are demanding it steps up on their behalf. In response, many western governments are taking their first tentative steps to place rules around the web and the way it interacts with and influences their societies. After all, that’s what government is supposed to do. In the US, the shock of the Trump victory has led to scrutiny of the role social networks and data breaches played in distorting the 2016 election outcome. In April 2018 Facebook’s chief, Mark Zuckerberg, was called before the US Senate to justify how his company pocketed money from Russian troll farms to boost fake news content and then enabled Trump’s data farmers, Cambridge Analytica, to scrape and exploit millions of its users’ profiles. Zuckerberg’s heavily scripted mea culpa was washed away with a global advertising campaign asserting that “data misuse is not our friend”, while clinging to the conceit that Facebook is nothing more than a humble platform. But that facade is cracking: Germany has brought in rules that regard social media companies as publishers with obligations to remove illegal content within 24 hours, including content that breaches anti-discrimination and anti-harassment laws. Others are going further and arguing that the big tech companies need to be broken up in the public interest. With Facebook and Google appropriating the distribution of news and advertising, Apple dominant in hardware and Amazon’s products enjoying a privileged position on its retail platform, laws that were designed to curb the big winners of the industrial revolution are back under the microscope. The so-called gilded age of the late 19th century in the US saw a concentration of power in the hands of robber barons whose control of railroads, steel production and oil extraction was deemed to be damaging to the nation’s economy. This led to the anti-trust laws that gave the government the power to break up the largest monopolies in the public interest. These laws have been whittled away over the past 50 years but some observers, including Tim Berners-Lee, argue the tech behemoths should, at the very least, be required to make their proprietary software and data publicly available. In Australia, tentative steps and missteps are being made to bring the tech giants to heel. In late 2018 the Australian Competition and Consumer Commission recommended a specialist authority be set up with the power to oversee the way Google and Facebook use their algorithms to reinforce their market dominance of the media. At year’s end, federal parliament was locked in a separate debate about the state’s power to access encrypted communications that will set ground rules around the sovereignty of private online domains. The outcome of arguments pitting national security against web freedom will help define the evolving relationships between the state and the web. The most promising theatre of regulation, though, is emerging around our personal information. Data is the wild west of the digital world with its near infinite capacity to capture, record and monitor individuals and store that information. Everything we buy, everyone we interact with, everywhere we go, and even the abstractions and predictions that algorithms make about us based on that information can be captured and exploited. In July 2018 the Australian Human Rights Commission began the Human Rights and Technology Project, exploring technological change and its effect on human rights. Central is the individual’s right to privacy and control over how their data is collected and used. To the extent they exist, current rules focus on the idea of consent, that we allow a site to access and use our data by accepting its terms and conditions, which are typically couched in legal jargon that we never actually read, linked to a click-box that we have no option but to click. Acquiescence to these permissions has become the price of entry to many parts of the web, particularly when the platform offers something for free. The project will reference the world-leading Global Data Protection Regulation developed by the European Union. Under the regulation, the idea that you control your data footprint has been accepted and embedded with privacy protocols placing enforceable rules on how corporations harvest and then monetise personal information. Protections include the right to be unknown and the right to be able to delete your personal records from a business that is holding them. It also includes rights for portability of data allowing, for instance, a user to take their data with them when they change banks, obligations on a business to delete a customer’s records when the customer takes their business elsewhere, as well as stringent data-handling protocols. Adopting these principles in Australia would be a significant step towards taking responsibility for the way the digital economy affects our privacy. But it is still an inherently reactive stance, focusing on mitigating the damage of data use rather than imagining how people could actually take ownership of their digital footprint. The natural extension of notions of control and consent is the more radical idea that we should legally own our data and that anyone else who wants to use it should pay us for the privilege. In a world where data is a natural resource on the web and data-mining is a global growth industry, individuals could have a claim for a payment on the value derived from its use. The individual transactions would be tiny but, taken at scale and aggregated globally, the concept of data rights could become a way of redistributing the profound concentration of online-derived wealth we are witnessing today. In a world where this data is used to develop algorithms that ultimately replace many of our jobs, some value could be returned to us via individual accounts constantly topped up with these micro royalty payments. Just as a writer has rights over her words or a composer over his music, why shouldn’t the digital footprint we create be our property? It’s a philosophical question with profound implications. Given the state of copyright, where big tech argues any assertion of intellectual property stifles creativity, this is a challenging proposition. But the Global Data Protection Regulation’s assertion that individuals should have control over their data provides a starting point for the next contest of ideas. This is an edited extract of Peter Lewis’s Webtopia: The world wide wreck of tech and how to make the net work (New South, $32.99)