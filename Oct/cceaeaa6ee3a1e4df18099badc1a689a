The UK government’s porn block was a dead man walking for months, if not years. It is long overdue that this attempt to curb children’s access to online pornography is scrapped. Almost two years ago, a close colleague and I sat in a meeting with one of the policymakers who had recently been asked to implement the proposal. The pained look on his face when we queried his progress confirmed our suspicions that it was an impossible task. It was clear to many that the block could – and would – never come to pass. The plan did not have just one achilles heel – it had many. First, there were privacy concerns. By requiring identification such as credit card details to access online pornography, it would have created a potentially explosive data set linking personal identification to private sexual information. A gold mine for leaks and hacks. Anyone who was a teenager, or knows one, also recognises how quickly such a block would be circumvented: you would only need a parent’s credit card, a virtual private network or black-market proxy. Second, if a user does not own a credit card or other form of identification such as a driver’s licence, their option would be to verify their age at an approved store, a post office, for example. This would have put up barriers for people with little access to documentation to do something they have every right to do. Scientists and other stakeholders cannot access information about what the population is actually doing online After continuous delays, the porn block was quietly scrapped last week. But the government is working on its next digital dilemma. In her written statement, the culture secretary, Nicky Morgan, stated that the block would now be integrated into legislation announced in the Online Harms white paper. This paper, however, is just another instance of the government rushing to proclaim unimplementable digital policy proposals when subjected to public pressure. The beginning of 2019 was marked by the tragic suicide of Molly Russell, whose family spoke compellingly in the media about the dangers of self-harm images on Instagram. This public pressure led to the expedited release of the Online Harms white paper, which, like the porn block, sounded good initially but now looks more like a PR statement than sustainable policy. The government failed to define an online harm: how do you classify harm if some content on the internet is harmful for some, but not for others? Furthermore, no detail was provided about how companies would be held to account for this undefined harm. The new white paper is, therefore, just kicking the problem of policing the internet down the road; like the porn block, it seeks to alleviate the electorate’s worries by proposing policy that seems too good to be true. Politicians need to engage in difficult debates with public and industry in order to design policy proposals that go beyond pacifying the population to provide actionable results. We need to rapidly understand how new digital technologies affect our society. Such progress is, however, almost impossible because scientists and other stakeholders cannot access information about what the population is actually doing online. Even though such data is stored aplenty on servers of technology companies, it is proprietary information and out of bounds for public research. Concurrently, technology companies use this same data to understand us and fine-tune their algorithms. It is time politicians enabled public research to inform policy proposals that are fit for purpose in the digital age. • Dr Amy Orben is a research fellow at Emmanuel College and the MRC Cognition and Brain Sciences unit, University of Cambridge